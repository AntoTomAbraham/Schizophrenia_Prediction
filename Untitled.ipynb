{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73c9400d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StandardScaler3D' object has no attribute 'fit_transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Standardize data\u001b[39;00m\n\u001b[1;32m     41\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler3D()\n\u001b[0;32m---> 42\u001b[0m train_features \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m(train_features)\n\u001b[1;32m     43\u001b[0m val_features \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(val_features)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Model architecture\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'StandardScaler3D' object has no attribute 'fit_transform'"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import scipy.io\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import mne\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, GRU, Conv1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "class StandardScaler3D(tf.keras.utils.Sequence):\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Reshape to 2D before fitting\n",
    "        X_reshaped = X.reshape(-1, X.shape[-1])\n",
    "        self.scaler.fit(X_reshaped)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Reshape to 2D before transforming\n",
    "        X_reshaped = X.reshape(-1, X.shape[-1])\n",
    "        X_transformed = self.scaler.transform(X_reshaped)\n",
    "        return X_transformed.reshape(X.shape)\n",
    "\n",
    "# Rest of the code remains the same...\n",
    "\n",
    "# Training loop with hyperparameter tuning\n",
    "accuracy = []\n",
    "\n",
    "for train_index, val_index in gkf.split(data_array, label_array, groups=group_array):\n",
    "    train_features, train_labels = data_array[train_index], label_array[train_index]\n",
    "    val_features, val_labels = data_array[val_index], label_array[val_index]\n",
    "\n",
    "    # Standardize data\n",
    "    scaler = StandardScaler3D()\n",
    "    train_features = scaler.fit_transform(train_features)\n",
    "    val_features = scaler.transform(val_features)\n",
    "\n",
    "    # Model architecture\n",
    "    input_layer = Input(shape=(1000, 19))\n",
    "    block1 = block(input_layer)\n",
    "    block2 = block(block1)\n",
    "    block3 = block(block2)\n",
    "\n",
    "    gru_out1 = GRU(32, activation='tanh', return_sequences=True)(block3)\n",
    "    gru_out2 = GRU(32, activation='tanh', return_sequences=True)(gru_out1)\n",
    "    gru_out = concatenate([gru_out1, gru_out2], axis=2)\n",
    "    gru_out3 = GRU(32, activation='tanh', return_sequences=True)(gru_out)\n",
    "    gru_out = concatenate([gru_out1, gru_out2, gru_out3])\n",
    "    gru_out4 = GRU(32, activation='tanh')(gru_out)\n",
    "\n",
    "    predictions = Dense(1, activation='sigmoid')(gru_out4)\n",
    "    model = Model(inputs=input_layer, outputs=predictions)\n",
    "\n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Learning rate schedule\n",
    "    def lr_schedule(epoch):\n",
    "        lr = learning_rate * 0.9 ** epoch\n",
    "        return lr\n",
    "\n",
    "    # Training with learning rate schedule\n",
    "    history = model.fit(\n",
    "        train_features, train_labels,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(val_features, val_labels),\n",
    "        callbacks=[LearningRateScheduler(lr_schedule)]\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on a validation set\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val_features, val_labels))\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "    evaluation = model.evaluate(val_dataset)\n",
    "\n",
    "    accuracy.append(evaluation[1])\n",
    "\n",
    "# Print the average accuracy over all folds\n",
    "print(\"Average Accuracy:\", np.mean(accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6987f48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
